{"./":{"url":"./","title":"Introduction","keywords":"","body":"Ningbo Zhao .newspaper {column-count:2;column-gap:40px;column-rule-style:dotted;} 注意: Internet Explorer 9及更早 IE 版本浏览器不支持 column-count 属性。 当我年轻的时候，我梦想改变这个世界；当我成熟以后，我发现我不能够改变这个世界，我将目光缩短了些，决定只改变我的国家；当我进入暮年以后，我发现我不能够改变我们的国家，我的最后愿望仅仅是改变一下我的家庭，但是，这也不可能。当我现在躺在床上，行将就木时，我突然意识到：如果一开始我仅仅去改变我自己，然后，我可能改变我的家庭；在家人的帮助和鼓励下，我可能为国家做一些事情；然后，谁知道呢?我甚至可能改变这个世界。 "},"Summary.html":{"url":"Summary.html","title":"Summary","keywords":"","body":"Summary Introduction Summary Ningbo Zhao 数据科学知识模型 test 计量统计 统计学要解决什么问题？ 统计学大纲 时间序列 逐波序列 生物信息效益 机器学习 机器学习的数学基础 降维 信息熵 模拟神经网络 📓 监督学习 监督学习和无监督学习 回归 线性回归 分类 逻辑回归 分类 SVM 回归/分类 KNN 决策树 贝叶斯 XGBoost 📓 无监督学习 K-Means EM PCA 可视化 Awesome dataviz QGIS 数据分析 Hive 时间函数 使用 Shell 发邮件 Leecode 185. 部门工资前三高的员工 601. 体育馆的人流量 615. 618. 课程 人大统计硕士笔记 中国特色社会主义理论与实践 高等统计学(数理统计学) 统计思想综述 抽样技术与方法 专业外语（英语） 马克思主义与社会科学方法论 《资本论》选读 多元统计分析 数据挖掘方法与应用 定性数据研究方法 统计预测 宏观经济统计分析 经济统计研究 统计诊断 市场研究 资本存量估算研究 针对中国的综合环境经济核算实施与建模研究 全球化背景下中国对外经济统计与计量分析 环境经济核算国际经验追踪及环境会计研究 中国信息服务业发展与影响研究 blog 201908 旧金山 201802 北京 201704 Trips in Nanjing 201703 Hot Card 201702 日本 北海道 201904 日本 东京 201801 日本 历史 201701 日本 东京博物馆 201902 北京 法源寺 201909 加州大学伯克利分校东亚图书馆 201907 北京 雍和宫 201801 北京 八大处 201010 北京 海淀 201903 北京 草场地第3年 201904 沈阳 再见东北 2019 旧金山 2018 北京 201004 泰拉瑞亚 201308 大学 201301 高考 About 赵宁波(Ningbo Zhao) 数据分析师，目前在美团工作。 邮箱：ningincn@hotmail.com "},"sis/0ningbozhao.html":{"url":"sis/0ningbozhao.html","title":"Ningbo Zhao","keywords":"","body":"Nan Gao is a PhD candidate in Computer Science at RMIT University, Melbourne. I finished my Masters and Bachelors in Software Engineering from Beijing Institute of Technology in 2018 and 2016. My main research interests are human behaviour analytics, indoor thermal comfort modelling, and applied machine learning for smart buildings and wearable sensings. I am currently a PhD candidate in Computer Science at RMIT University working with A/Prof. Flora Salim, Dr. Wei Shao and Dr. Mohammad Saiedur Rahaman. My PhD thesis is Quality-aware Predictive Analytics of Occupant Behaviour and Thermal Comfort, which is funded by ARC linkage program (No. LP150100246). Industry Partner of my research is Aurecon. E-mail:ningincn@hotmail.com Wechat:ningincn Weibo:ningbro what i need I finished my Masters and Bachelors in Software Engineering from Beijing Institute of Technology in 2018 and 2016\\. My main research interests are human behaviour analytics, indoor thermal comfort modelling, and applied machine learning for smart buildings and wearable sensings. LBS 六边形地域分析体系I finished my Masters and Bachelors in Software Engineering from Beijing Institute of Technology in 2018 and 2016\\. My main research interests are human behaviour analytics, indoor thermal comfort modelling, and applied machine learning for smart buildings and wearable sensings. 模拟神经网络I finished my Masters and Bachelors in Software Engineering from Beijing Institute of Technology in 2018 and 2016\\. My main research interests are human behaviour analytics, indoor thermal comfort modelling, and applied machine learning for smart buildings and wearable sensings. 精细化网格城市运营模型I finished my Masters and Bachelors in Software Engineering from Beijing Institute of Technology in 2018 and 2016\\. My main research interests are human behaviour analytics, indoor thermal comfort modelling, and applied machine learning for smart buildings and wearable sensings. 集中趋势分析I finished my Masters and Bachelors in Software Engineering from Beijing Institute of Technology in 2018 and 2016\\. My main research interests are human behaviour analytics, indoor thermal comfort modelling, and applied machine learning for smart buildings and wearable sensings. Homepage – PhD Candidate in RMIT University ABOUT ME PUBLICATIONS SELECTED AWARDS HOBBIES BELIEVED QUOTES CONTACT 用户分层与流动 2019-08-11 在互联网+和大数据快速发展的今天，统计学院面向社会服务已经取得辉煌的成就，中国社会调查数据中心，统计建模、随机分析及应用、抽样技术及应用、统计数据库与数据挖掘、多元统计分析等研究，培养了一大批优秀的高级应用统计人才进入政府公务员和经济、社会、金融、保险、管理等领域工作，建设了一些有针对社会需要的统计调查和数据分析研究平台体系，与国际一流大学和研究机构合作，不断提升为国家发展强大做出贡献的能力。 用户分层与流动 2019-08-11 在互联网+和大数据快速发展的今天，统计学院面向社会服务已经取得辉煌的成就，中国社会调查数据中心，统计建模、随机分析及应用、抽样技术及应用、统计数据库与数据挖掘、多元统计分析等研究，培养了一大批优秀的高级应用统计人才进入政府公务员和经济、社会、金融、保险、管理等领域工作，建设了一些有针对社会需要的统计调查和数据分析研究平台体系，与国际一流大学和研究机构合作，不断提升为国家发展强大做出贡献的能力。 用户分层与流动 2019-08-11 在互联网+和大数据快速发展的今天，统计学院面向社会服务已经取得辉煌的成就，中国社会调查数据中心，统计建模、随机分析及应用、抽样技术及应用、统计数据库与数据挖掘、多元统计分析等研究，培养了一大批优秀的高级应用统计人才进入政府公务员和经济、社会、金融、保险、管理等领域工作，建设了一些有针对社会需要的统计调查和数据分析研究平台体系，与国际一流大学和研究机构合作，不断提升为国家发展强大做出贡献的能力。 用户分层与流动 2019-08-11 在互联网+和大数据快速发展的今天，统计学院面向社会服务已经取得辉煌的成就，中国社会调查数据中心，统计建模、随机分析及应用、抽样技术及应用、统计数据库与数据挖掘、多元统计分析等研究，培养了一大批优秀的高级应用统计人才进入政府公务员和经济、社会、金融、保险、管理等领域工作，建设了一些有针对社会需要的统计调查和数据分析研究平台体系，与国际一流大学和研究机构合作，不断提升为国家发展强大做出贡献的能力。 用户分层与流动 2019-08-11 在互联网+和大数据快速发展的今天，统计学院面向社会服务已经取得辉煌的成就，中国社会调查数据中心，统计建模、随机分析及应用、抽样技术及应用、统计数据库与数据挖掘、多元统计分析等研究，培养了一大批优秀的高级应用统计人才进入政府公务员和经济、社会、金融、保险、管理等领域工作，建设了一些有针对社会需要的统计调查和数据分析研究平台体系，与国际一流大学和研究机构合作，不断提升为国家发展强大做出贡献的能力。 欢迎使用 Arya 在线 Markdown 编辑器 Arya，是一款基于 Vue、Vditor，为未来而构建的在线 Markdown 编辑器；轻量且强大：内置粘贴 HTML 自动转换为 Markdown，支持流程图、甘特图、时序图、任务列表，可导出携带样式的图片、PDF、微信公众号特制的 HTML 等等。 微注：清空目前这份默认文档，即处于可使用态。Arya 另一大优点在于：编辑内容只会在您本地进行保存，不会上传您的数据至服务器，绝不窥测用户个人隐私，可放心使用；Github 源码：markdown-online-editor，部分功能仍在开发🚧，敬请期待。 什么是 Markdown Markdown 是一种方便记忆、书写的纯文本标记语言，用户可以使用这些标记符号，以最小的输入代价，生成极富表现力的文档：譬如您正在阅读的这份文档。它使用简单的符号标记不同的标题，分割不同的段落，粗体、斜体 或者超文本链接，更棒的是，它还可以： 1. 制作待办事宜 Todo 列表 [x] 🎉 通常 Markdown 解析器自带的基本功能； [x] 🍀 支持流程图、甘特图、时序图、任务列表； [x] 🏁 支持粘贴 HTML 自动转换为 Markdown； [x] 💃🏻 支持插入原生 Emoji、设置常用表情列表； [x] 🚑 支持编辑内容保存本地存储，防止意外丢失； [x] 📝 支持实时预览，主窗口大小拖拽，字符计数； [x] 🛠 支持常用快捷键(Tab)，及代码块添加复制 [x] ✨ 支持导出携带样式的 PDF、PNG、JPEG 等； [x] ✨ 升级 Vditor，新增对 echarts 图表的支持； [ ] 🚧 支持转换 Markdown 到微信特制的 HTML； [ ] 🚧 内置多种漂亮样式，并且支持用户自定义； [ ] 🚧 支持检查并格式化 Markdown 语法，使其专业； 2. 书写一个质能守恒公式LaTeX E=mc2E=mc^2E=mc​2​​ 1+1=221+1=2^21+1=2​2​​ 3. 高亮一段代码code // 给页面里所有的 DOM 元素添加一个 1px 的描边（outline）; [].forEach.call($$(\"*\"),function(a){ a.style.outline=\"1px solid #\"+(~~(Math.random()*(1 4. 高效绘制流程图 graph TD; 数据分析-->理论基础; 理论基础-->线性代数; 理论基础-->统计学; 数据分析-->代码语言; 代码语言-->Python; 代码语言-->Shell; 代码语言-->SQL(MySQL\\Hive\\Hadoop); 数据分析-->机器学习; 机器学习-->聚类 机器学习-->降维 5. 高效绘制序列图 sequenceDiagram participant Alice participant Bob Alice->John: Hello John, how are you? loop Healthcheck John->John: Fight against hypochondria end Note right of John: Rational thoughts prevail... John-->Alice: Great! John->Bob: How about you? Bob-->John: Jolly good! 6. 高效绘制甘特图 甘特图内在思想简单。基本是一条线条图，横轴表示时间，纵轴表示活动（项目），线条表示在整个期间上计划和实际的活动完成情况。它直观地表明任务计划在什么时候进行，及实际进展与计划要求的对比。 gantt title 项目开发流程 section 项目确定 需求分析 :a1, 2019-06-22, 3d 可行性报告 :after a1, 5d 概念验证 : 5d section 项目实施 概要设计 :2019-07-05 , 5d 详细设计 :2019-07-08, 10d 编码 :2019-07-15, 10d 测试 :2019-07-22, 5d section 发布验收 发布: 2d 验收: 3d 7. 支持图表 { \"backgroundColor\": \"#212121\", \"title\": { \"text\": \"「晚晴幽草轩」访问来源\", \"subtext\": \"2019 年 6 月份\", \"x\": \"center\", \"textStyle\": { \"color\": \"#f2f2f2\" } }, \"tooltip\": { \"trigger\": \"item\", \"formatter\": \"{a} {b} : {c} ({d}%)\" }, \"legend\": { \"orient\": \"vertical\", \"left\": \"left\", \"data\": [ \"搜索引擎\", \"直接访问\", \"推荐\", \"其他\", \"社交平台\" ], \"textStyle\": { \"color\": \"#f2f2f2\" } }, \"series\": [ { \"name\": \"访问来源\", \"type\": \"pie\", \"radius\": \"55%\", \"center\": [ \"50%\", \"60%\" ], \"data\": [ { \"value\": 10440, \"name\": \"搜索引擎\", \"itemStyle\": { \"color\": \"#ef4136\" } }, { \"value\": 4770, \"name\": \"直接访问\" }, { \"value\": 2430, \"name\": \"推荐\" }, { \"value\": 342, \"name\": \"其他\" }, { \"value\": 18, \"name\": \"社交平台\" } ], \"itemStyle\": { \"emphasis\": { \"shadowBlur\": 10, \"shadowOffsetX\": 0, \"shadowColor\": \"rgba(0, 0, 0, 0.5)\" } } } ] } 备注：上述 echarts 图表📈，其数据，须使用严格的 JSON 格式；您可使用 JSON.stringify(data)，将对象传换从而得标准数据，即可正常使用。 8. 绘制表格 作品名称 在线地址 上线日期 倾城之链 https://nicelinks.site 2017-09-20 晚晴幽草轩 https://jeffjade.com 2014-09-20 静轩之别苑 http://quickapp.lovejade.cn 2019-01-12 9. 更详细语法说明 想要查看更详细的语法说明，可以参考这份 Markdown 资源列表，涵盖入门至进阶教程，以及资源、平台等信息，能让您对她有更深的认知。 总而言之，不同于其它所见即所得的编辑器：你只需使用键盘专注于书写文本内容，就可以生成印刷级的排版格式，省却在键盘和工具栏之间来回切换，调整内容和格式的麻烦。Markdown 在流畅的书写和印刷级的阅读体验之间找到了平衡。 目前它已经成为世界上最大的技术分享网站 GitHub 和 技术问答网站 StackOverFlow 的御用书写格式，而且越发流行，正在在向各行业渗透。 最新更新于 2019.07.13 # 这是注释 title: 这是标题 A->B: 正常的线 B-->C: 虚线 C->>D: 开口箭头 D-->>A: 虚线开口箭头 participant C participant B participant A Note right of A: 列举参与者\\n 你可以修改它们的顺序 数据分析-->理论基础: 正常的线 理论基础-->线性代数: 正常的线 理论基础-->统计学: 正常的线 数据分析-->代码语言: 正常的线 代码语言-->Python: 正常的线 代码语言-->Shell: 正常的线 代码语言-->SQL(MySQL\\Hive\\Hadoop): 正常的线 数据分析-->机器学习: 正常的线 机器学习-->聚类: 正常的线 机器学习-->降维: 正常的线 st=>start: 开始 e=>end: 结束 op=>operation: 我的操作 cond=>condition: 确认？ st->op->cond cond(yes)->e cond(no)->op A[Hard edge] -->B(Round edge) B --> C{Decision} C -->|One| D[Result one] C -->|Two| E[Result two] "},"sis/datascience.html":{"url":"sis/datascience.html","title":"数据科学知识模型","keywords":"","body":"数据科学知识模型 找了一些对数据分析师和数据科学家的要求，总结了以下知识点： 数据库：Hadoop MySQL脚本：Shell分析语言：Python R分析工具：SPSS MATLAB s 数据库：Hadoop MySQL脚本：Shell分析语言：Python R分析工具：SPSS MATLAB s 数理统计 描述统计假设检验线性回归时间序列指数学习基础的描述统计学理论、基本的概率知识、二项分布和贝叶斯公式，并学会使用 Python 来实践；学习正态分布、抽样分布、置信区间以及假设检验的概念和计算方式；学习线性回归以及逻辑回归，在真实场景中应用，比如分析 A/B 测试结果，搭建简单的监督机器学习模型。 Python连接数据库导出导入 csv/xlsx 文件操作数据，转置、排序、修改、增删绘制图形时间函数进行描述性统计进行预测 机器学习知识 线性回归、代价函数、梯度下降、多项式线性拟合正规方程特征处理逻辑回归正则神经网络设计误差分析支持向量机聚类PCA 主成分分析异常检验推荐系统协同过滤 机器学习基础 学习机器学习的基础知识，初步了解一些机器学习可以完成的任务，如分类与回归问题，包括机器学习涉及到的统计分析知识以及模型评估和验证知识。实战项目：预测波士顿房价案例演练：泰坦尼克号乘客生存率分析案例演练：预测你的下一道世界料理 监督学习 监督学习是通过已标注过的训练数据来完成分类或回归任务的一类机器学习方法。学习决策树、神经网络、支持向量机等监督学习算法。实战项目：为慈善机构寻找捐赠者案例演练：游戏玩家付费金额预测案例演练：为信贷公司搭建金融风控模型案例演练：企业广告点击率预测 非监督学习 当数据样本没有标签的情况下，非监督学习是其解决问题的最佳方案。学习聚类，特征工程和降维等非监督学习算法。实战项目：创建客户细分案例演练：电影评分的 K-MEANS 聚类案例演练：使用特征脸方法和 SVM 进行脸部识别 深度学习基础 深度学习是当今世界上非常火热的一类机器学习方法，在许多领域中甚至超过了人类的能力。学会使用 Tensorflow，并且学习卷积神经网络等知识。 Python 中的线性代数 学习人工智能领域必备的数学知识：向量、线性变换和矩阵。你还将更深入地学习神经网络背后的线性代数。 解决问题：1- 利用机器学习模型预测股票走势；2- 为某平台搭建金融风控模型；3- 为某集团打造用户分层模型。 名词 英文 作用 实践 聚类分析 Cluster 目的：探索样本的同质组，将相似的对象组成一个簇。用于分析簇之间的差异和相似性。案例：将用户群根据消费次数/消费类型等分成 3 类。 python 比较分析 Comparative 目的：使用模式分析、过滤和决策树等来比较多个数据集。案例：在医疗领域，通过比较大量的医疗记录、文件、图像等，给出更准确的医疗判断。 关联分析 Connection 相关性分析 Correlation 目的：分析变量之间是否存在正相关/负相关。 异常值检测 Outlierdetection 异常值是严重偏离一个数据集或总平均值的对象，需要另加分析或剔除。 回归分析 Regressionanalysis 目的：确定两个变量间的依赖关系。这种方法假设两个变量之间存在单向的因果关系（自变量 因变量）。 主成分分析降维 线性回归 PV Page View 页面浏览量，不去重，刷新也计算 UV Unique Vistor 独立访客，根据 Cookie 去重 Bounce Rate 跳出率 用户模型(客户评估模型) RFM 模型 客户价值分析模型R：Regency（近度），即客户最近一次交易与当前时间的间隔。F：Requency（频度），即客户的交易频率。M：Montary（额度），即客户的交易金额。 忠诚度模型 活跃度模型 客户细分模型 Look-alike 模型 客户响应模型 流失预警模型 大数据基础知识考试内容： 了解大数据的定义、特点等 了解数据的类型和丌同的分析处理方法 了解大数据相关的概念、实际的应用案例、适用的场景等 了解云计算的特点、云计算不大数据的关系 了解大数据相关的技术，如存储、计算、分析等 了解大数据职业的特点不对人才的要求 大数据存储技术考试内容 了解分布式存储技术的概念不特点 了解数据存储技术适用的丌同场景，包括数据类型（如结构化、半结 构化、非结构化数据）、数据容量、使用场景等 了解数据库的基本概念不特点，包括可靠性、约束、三范式、适用场 景等 了解数据仓库的基本概念不特点，包括不数据库的区别、ETL 等 了解 HDFS 不 MaxCompute 的构成不特点 了解文件存储、数据库存储、分布式存储之间的优缺点 掌握大数据计算服务的数据上传和下载，可以熟练使用 MySQL、HDFS、 MaxCompute 等进行数据存储 了解 Hadoop、MaxCompute 等产品的基本概念不特点，包括应用 场景和局限性 数据分析工具考试内容 掌握大数据计算服务的 SQL 命令，包括 DDL、DML 以及常见内置函数 了解 MapReduce 的基本概念不特点 能够使用 DataIDE 的数据开发模块进行设计开发，包括建表、任务开发、数据上传等 能够使用 MySQL、MaxCompute、Hive 平台进行数据分析 数据可视化考试内容 了解数据可视化的基本知识，如定义、特点、实现方式等 了解 Quick BI、DataV 的产品特点和使用场景 了解常见图表类型的特点和适用场景 能够使用 Quick BI 设计开发报表和门户 了解可视化产品的分类和基本设计原则 数据编程考试内容 掌握数据预处理的基本方法 了解描述性统计分析的概念和特点，包括常见统计量、概率分布、拟 合不检验 了解假设检验的概念和特点，能够根据应用场合真确使用正态分布单 样本和双样本和二项分布假设检验 能够基于项目的目标不范围规划数据分析方案，设计合理的指标 了解数据分析编程的特点，包括编程手法、编程效率、编程规范和质 量控制 了解指标体系的概念，包括总量指标、结构指标和平均指标，并能够 合理应用达到数据分析目的 掌握数据分析报告撰写的规范 数据项目质量控制考试内容 了解数据质量的 5 个维度的概念和特点 了解在数据质量的 5 个维度基础上，脏数据的种类、来源、造成的影响 掌握处理脏数据的方法，包括对脏数据的检查、修复、清洗、转换等 了解数据质量问题在数据编程过程中发生的原因，并能够利用质量检 验的技术手段保证项目的顺利执行 了解项目的目标是数据分析项目中衡量数据质量的主要标准，并能够 判断数据中的质量问题是否对数据分析项目产生影响 数据项目设计不执行考试内容 了解项目工程管理方法论的定义、特点和实际应用场景 能够理解数据分析项目的实施流程、重点环节、数据项目执行流程的 重要性 掌握项目设计的特点，包括业务问题数据化、明确项目的目的、范围、 和分析维度等 能够利用项目绩效分析实现项目后数据分析 能够利用现状、原因、预测的分析方法实现项目前数据分析 了解临时性项目不经常性项目之间的区别 机器学习考试内容 了解机器学习常见的算法，如聚类、决策树、关联分析等 了解机器学习的常见使用流程，包括算法调优和效果评估 能够使用聚类分析，包括 K-means 算法对相似的顾客分类 能够使用决策树算法生成商业规则 能够使用关联分析实现购物篮分析 | 级别 | Level I | Level II | Level II | Level III | |---------|-----------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------| | （业务分析师） | （建模分析师） | （大数据分析师） | （数据科学家） | | 理论 | 概率论、统计学理论基础 | 统计学、概率论和数理统计、多元统计分析、时间序列、数据挖掘 | 概率论和数理统计、Python基础、Linux基础、数据挖掘和机器学习 | 统计学、大数据、机器学习、数据治理和项目管理 | | 基础 | | 软件 | 必要：Excel、SQL | 必要：Excel、SQL | 必要： SQL、Hadoop、HDFS、Mapreduce、Hbase、Hive、Sqoop、Spark | 必要：Excel、SQL、Python、Hadoop、Spark | | 要求 | 可选：Python、SPSS、R等 | 可选：Python、R、SPSS Modeler、Spark等 | 可选：Kafka、Flume、ZooKeeper等 | 可选：R、SAS、Tensorflow等 | | 分析方 | 掌握基本数据预处理方法，SQL数据库技术，数据分析方法（描述性统计分析，推断性统计分析，方差分析，线性回归等）；市场调研（数据报告），常用数据分析模型（聚类分析、逻辑回归、时间序列等）。 | 除掌握基本数据处理及分析方法以外，还应掌握高级数据分析及数据挖掘方法（特征工程、贝叶斯、决策树、神经网络、支持向量机、集成方法、关联规则、序列模式等）和可视化技术。 | 熟练掌握hadoop集群搭建；熟悉nosql数据库的原理及特征，并会运用在相关的场景；熟练运用Spark及Spark MLLib算法库提供的进行大数据分析的数据挖掘算法，包括无监督算法（k\\-means算法、DBSCAN算法、FP\\-Growth）、有监督学习算法（决策树、SVM、贝叶斯、集成算法、神经网络、协同过滤）等算法的原理和使用范围 | 除掌握数据分析和挖掘的方法之外,还需了解数据治理技术，计算机编程技术，机器学习，人工智能，大数据分析架构以及业务分析方法，包括代码管理、敏捷分析、战略分析，产品管理，风险管理、客户关系管理，项目管理，运营管理等结合具体行业的业务分析方法。 | | 法要求 | | 业务分 | 熟知业务，能够根据问题业务指标提取公司数据库中相关数据，进行整理、清洗、处理，通过相应数据分析方法，结合软件平台应用完成对数据的分析和报告。 | 可以将业务目标转化为数据分析目标；熟悉常用算法和数据结构，熟悉企业数据库构架建设；针对不同分析主体，可以熟练的进行维度分析，能够从海量数据中搜集并提取信息；通过相关数据分析方法，结合一个或多个数据分析软件完成对海量数据的处理和分析。 | 熟悉hadoop\\+hive\\+spark进行大数据分析的架构设计，并能针对不同的业务提出大数据架构的解决思路。掌握hadoop\\+hive\\+ Spark\\+tableau平台上Spark MLlib、SparkSQL的功能与应用场景，根据不同的数据业务需求选择合适的组件进行分析与处理。并对基于Spark框架提出的模型进行对比分析与完善。 | 带领数据团队，能够将企业的数据资产进行有效的整合和管理，建立内外部数据的连接；熟悉数据仓库的构造理论，可以指导ETL工程师业务工作；可以面向数据挖掘运用主题构造数据集市；在人和数据之间建立有机联系，面向用户数据创造不同特性的产品和系统；具有数据规划的能力。 | | 析能力 | | 结果展 | 能够形成逻辑清晰的报告，传递分析结果，对实际业务提出建议和策略。 | 报告体现数据挖掘的整体流程，层层阐述信息的收集、模型的构建、结果的验证和解读，对行业进行评估，优化和决策。 | 报告能体现大数据分析的优势，能清楚地阐述数据采集、大数据处理过程及最终结果的解读，同时提出模型的优化和改进之处，以利于提升大数据分析的商业价值。 | 报告形式多样化，图文并茂，逻辑严密。为企业数据资产管理提供详细方案，对企业发展提供数据规划策略。 | | 现能力 | "},"sis/test.html":{"url":"sis/test.html","title":"test","keywords":"","body":"type1 graph TD; A-->B; A-->C; B-->D; C-->D; graph TD 0(Machine Learning) --> i1(supervised learning) 0 --> i2(unsupervised learning) 0 --> i3(数学基础) 0 --> i4(big wide) 0 --> i5(more wide) 0 --> |for test|i6(more and more wide) 0 --> |for test again|i7(more and more and more wide) i1 --> he[fa:fa-car Car] i1 --> |Get money| she i2 --> K-Means i2 --> PCA i3 --> m1(线性代数) i3 --> m2(高等数学) i3 --> m3( ) i3 --> m4( ) i3 --> m5( ) PCA --> 降维 降维 --> i1 graph TD 0(Machine Learning) --> i1(supervised learning) 0 --> i2(unsupervised learning) 0 --> i3(数学基础) 0 --> i4(big wide) 0 --> i5(more wide) 0 --> |for test|i6(more and more wide) 0 --> |for test again|i7(more and more and more wide) i1 --> he[fa:fa-car Car] i1 --> |Get money| she i2 --> K-Means i2 --> PCA i3 --> m1(线性代数) i3 --> m2(高等数学) i3 --> m3( ) i3 --> m4( ) i3 --> m5( ) PCA --> 降维 降维 --> i1 type3 graph TD 0(机器学习) --> i(监督学习) 0 --> i2(无监督学习) i --> he[fa:fa-car Car] i --> |Get money| she i2 --> K-Means i2 --> PCA 数据科学知识模型 模拟服务端数据 (xdxdy−ydydx)2\\left(\\frac{x d x}{d y}-\\frac{y d y}{d x}\\right)^{2}(​dy​​xdx​​−​dx​​ydy​​)​2​​ 在前面的章节中，我们设置了代理，于是所有的 HTTP 请求都可以先到达本地开发服务器，再被转发。在实际的开发中，后端的服务不一定马上可用，这就需要本地服务器另外一个能力：模拟数据（mock）。设置代理是 mock 的前提。 一个 ajax 请求发送到本地开发服务器后，我们可以设置：如果请求满足某个规则，则不转发这个请求，而是直接返回一个「假」结果给浏览器。在实际的开发中，我们常常先和服务端的同学商定 http 请求的接口接受什么参数，返回什么结果，然后先用 mock 数据来模拟，自己和自己「联调」。等待服务端同学开发好了，再解除 mock，用真实数据「联调」。 模拟正常返回数据 设置模拟数据时需要在工程根目录下的 mock 子目录中的建立文件。首先在工程中增加 mock 目录，并在其中创建文件 puzzlecards.js（取其他名字也可以，名字这里不需要）。如果想 mock 掉我们在上一个章节中的向 /dev/random_joke 的 ajax 调用，需要写入以下内容到文件， const random_jokes = [ { setup: 'What is the object oriented way to get wealthy ?', punchline: 'Inheritance', }, { setup: 'To understand what recursion is...', punchline: \"You must first understand what recursion is\", }, { setup: 'What do you call a factory that sells passable products?', punchline: 'A satisfactory', }, ]; let random_joke_call_count = 0; export default { 'get /dev/random_joke': function (req, res) { const responseObj = random_jokes[random_joke_call_count % random_jokes.length]; random_joke_call_count += 1; setTimeout(() => { res.json(responseObj); }, 3000); }, }; 如果你不断地刷新页面，会发现每次拿到的数据是不同的。并且由于 setTimeout 的存在使得卡片的更新变慢了。 我们通过这个例子解释一下怎么写 mock 数据。 首先，整个文件需要 export 出一个 js 对象。对象的 key 是由 构成的，值是 function，当一个 ajax 调用匹配了 key 后，与之对应的 function 就会被执行。函数中我们调用 res.json 就可以给浏览器返回结果。函数中可以使用 setTimeout 来模拟异步调用服务时的时延。 模拟出错 利用 res.status 也可以模拟 http 请求出错。例如，我们把文件中的 export default 块替换成下面的内容， export default { 'get /dev/random_joke': function (req, res) { res.status(500); res.json({}); }, }; 在 dva model 中我们加入简单的错误捕获: import { message } from 'antd'; // ... 原有逻辑不修改 try { // 加入 try catch 捕获抛错 const puzzle = yield call(request, endPointURI); yield put({ type: 'addNewCard', payload: puzzle }); yield call(delay, 3000); const puzzle2 = yield call(request, endPointURI); yield put({ type: 'addNewCard', payload: puzzle2 }); } catch (e) { message.error('数据获取失败'); // 打印错误信息 } 于是可以看到出错状况下的页面： 在每一个调用点做打印错误信息很麻烦，这里只是为了展示 mock 出错场景。在实际的开发中，一般会统一处理 http 请求错误时的信息提示。 简单数据模拟 刚才的模拟中，mock 具备动态改变、延时返回等能力，如果你不需要这个能力，也可以简单地使用对象。 export default { 'get /dev/random_joke': { setup: 'What is the object oriented way to get wealthy ?', punchline: 'Inheritance', }, }; 深入理解 umi 本文介绍 umi 框架的一些深入概念，帮助大家理解背后的运行机制。 下图是 umi 的架构图，我们试着从此图来一步步理解 umi 。 基于路由 举个 SPA 的例子，比如我们访问 /users，会由 ./src/pages/users.js 决定具体渲染什么，按我们的理解，这其中 /users 是路由，./src/pages/users.js 是路由组件，他们俩组成了一个路由配置，然后多个路由配置又形成了一个完整的应用。不难发现，在这个应用里，路由即入口。 umi 是基于路由的，所以具备了管理入口的能力。你甚至可以简单地理解为 umi = 路由 + webpack，当然我们在此基础上做了很多额外的工作。然后，管理了入口之后，能做的事情就很多了。 比如： 开发时按需编译 运行时按需加载，做 code-splitting 智能提取公共代码，加速用户访问，通常是被 路由数/2 引用的模块才被提取到公共代码中 服务端渲染 基于路由的埋点 基于约定，如果 ./src/pages/404.js 存在则添加为 fallback 路由 ... 这里有很大的想象空间。 从源码到上线的生命周期管理 市面上的框架基本都是从源码到构建产物，很少会考虑到各种发布流程，而 umi 则多走了这一步。 下图是 umi 从源码到上线的一个流程。 umi 首先会加载用户的配置和插件，然后基于配置或者目录，生成一份路由配置，再基于此路由配置，把 JS/CSS 源码和 HTML 完整地串联起来。用户配置的参数和插件会影响流程里的每个环节。 举个例子，比如以下目录： + src + layouts/index.js + pages - a.js - b.js - 404.js 会生成路由配置如下： { component: 'layouts/index.js', routes: [ { path: '/a', exact: true, component: 'pages/a.js' }, { path: '/b', exact: true, component: 'pages/b.js' }, { component: 'pages/404.js' }, ], } 以及可运行的代码： const routes = { component: require('layouts/index.js'), routes: [ { path: '/a', exact: true, component: require('pages/a.js') }, { path: '/b', exact: true, component: require('pages/b.js') }, { component: require('pages/404.js') }, ], }; export default () => { renderRoutes(routes) } 另外，HTML 也是一个很重要的环节，因为他才是真正的入口，js 和 css 都是在 HTML 里发起的。HTML 在 umi 里是一等公民，这意味着我们可以通过插件来调整他的输出，以便和各个后台系统对接，以及打通各种发布流程。 举个例子，我们要配置 webpack externals 掉 react 来优化构建产物，通常我们要做两步： 配置 externals: { react: 'window.React' } 在 html 里引入 https://unpkg.com/react@16.4.1/cjs/react.production.min.js 这里的问题是一个功能需要在两个地方维护并且一一对应。然后在 umi 里，由于 HTML 具备插件的能力，所以可以做到你只需要完成第一步，然后 umi 自动帮你做第二步。 最后，通过 umi 可以把各种部署方式封装成插件，实现同一份源码，装载不同的插件，就可以部署到不同平台。比如 umi + umi-plugin-deploy-offline 可以部署为离线包；umi + umi-plugin-deploy-chair 可以部署到 chair 系统。 插件机制 关于 umi 的插件机制你可以阅读 umi 的文档《插件开发》来了解更多。 "},"Sis/sis统计学要解决什么问题.html":{"url":"Sis/sis统计学要解决什么问题.html","title":"统计学要解决什么问题？","keywords":"","body":""},"Sis/sis统计学大纲.html":{"url":"Sis/sis统计学大纲.html","title":"统计学大纲","keywords":"","body":""},"Sis/sis时间序列.html":{"url":"Sis/sis时间序列.html","title":"时间序列","keywords":"","body":"时间序列 "},"Sis/sis逐波序列.html":{"url":"Sis/sis逐波序列.html","title":"逐波序列","keywords":"","body":""},"Sis/sis生物信息效益.html":{"url":"Sis/sis生物信息效益.html","title":"生物信息效益","keywords":"","body":""},"Sis/math00.html":{"url":"Sis/math00.html","title":"机器学习的数学基础","keywords":"","body":"数学基础知识 1.符号、定义 1.1根式 1.2对数 1.3向量 1.4导数 1.5定积分 1.6微积分 1.7偏导数 偏导数的几何意义： 1.8 矩阵 矩阵的迹：在线性代数中，一个n×n矩阵A的主对角线（从左上方至右下方的对角线）上各个元素的总和被称为矩阵 A的迹（或迹数），一般记作tr(A)。 矩阵与向量 二阶矩阵变换 1.9 标准差 量化数据离散程度的方法： 极差 = 最大值 — 最小值。但只有两个数据来评判一组数据，是不科学的。 离均差 (deviation from mean)= 数据 — 均值。因为离散度是数据偏离均值的程度，可以将离均差累加，来衡量离散程度；但离均差有正有负，所以一般用离均差的绝对值之和，或离均差的平方和，衡量离散程度。 方差：离均差平方和的平均值。离均差的平方和的大小和样本数量有关，为了增加可比性，对离均差的平方和求平均值。 标准差：方差的算术平方根。方差是数据的平方，与检测值本身相差较大，所以用方差开根号来衡量离散度。 2.公式、定理、性质 2.1对数 2.2导数、积分 【问题引出】求函数曲线的切线？求曲线形的面积？ 【基本思想】求导和求积分是互为逆运算，运算的对象是函数/曲线，求导和求积分的基本思想是以直代曲、用高倍放大镜观察一条曲线的微小片段。 2.2.1矩阵的导数 2.3高阶偏导数 2.4矩阵 3.函数 3.1指数函数 3.2对数函数 3.3幂函数 "},"Sis/ml降维.html":{"url":"Sis/ml降维.html","title":"降维","keywords":"","body":"Back from rstudio::conf 2019 Observations, experiences, thoughts, and Q&A Yihui Xie / 2019-01-25 There was an obvious reason for me being quiet in my blog this month: the rstudio::conf(2019) took place last week. I (co-)taught a workshop and gave a talk there, so I needed a lot of time to make the preparation. In this post, I want to share some observations and experiences. Note that this is not a summary of the conference. Many others have blogged about the conference, and you can find those links in Karl’s Github repo. Some people I met Usually I don’t have much interest in meeting anyone in person because the online connection seems to be good enough for me. Sometimes I feel there is no real need to physically meet someone. For example, the total time I have literally talked to Karthik Ram should be no more than five minutes, but I feel we just know each other so well and have been paying attention to each other’s work over the years. That said, I definitely don’t avoid meeting people deliberately. At the R Markdown workshop, I met Stas Kolenikov and Josh Goldberg (for the first time, I think). I started to notice Josh since last year because of his several comments in my blog. If all students were of his level in rmarkdown and knitr, I’m afraid I wouldn’t have much left to teach in the workshop. Stas seems to be active on Twitter, and he actually suggested that I cover David Gohel’s officer package in the R Markdown workshop. That was not on my original plan, but after Eric Nantz offered to help, I accepted the officer tutorial without hesitation, because I thought it would be great for the students to know the alternatives to R Markdown (and R Markdown is certainly not perfect for everything). Of course, it was great to meet my co-instructor (and now colleague) Alison for the first time in person. She is such a great and enthusiastic instructor! I admire her capability of learning things quickly and teaching them clearly. BTW, I think she is absolutely the top expert of the hugo-academic theme now. I don’t remember if it was also the first time I had met our TA Jennifer Thompson. I mentioned her last year in a blog post. Apparently Alison did a great job at finding TAs for our workshop. Other awesome TAs include Jiena Gu, Hao Zhu, and Thomas Mock. I asked Jiena to be TA because she had asked me a lot of questions about R Markdown and Shiny in the past. Many people ask me questions, but she is one of the few who can dig much deeper and work out amazing solutions by themselves after I provide my hints or even guesses. Hao is famous at least for his work on the kableExtra package. At JSM 2018, someone just called him “the kable guy”. One random person I happily and surprisingly bumped into was Suthira Owlarn during a lunch. It was a few minutes into our conversation that I realized she was the person who mentioned my moon cake recipe two months ago! Sitting on my left-hand side at the same lunch table was Hiroaki Yutani. I had never met him before, but I was actively looking for him at the conference. He had a poster but his flight was late, so I didn’t find him in front of his poster. I have discovered several cool Japanese hackers on Github in these years, including Hiroaki. Last year I decided to give him write access to the knitr repo because I felt he was careful enough and knew well enough about the source code of knitr. He was actually the first person who gained write access to the knitr repo besides me. Personally I’m very interested in the Japanese culture, and I wish I could spend a few months living in Japan someday. I met Christophe Dervieux for the second time at rstudio::conf. I cannot thank him enough for his active help with my Github issues almost on a daily basis. During the 2018 rstudio::conf, I talked to him briefly about automating the generation of the bookdown.org website, and he quickly finished what I planned to do, which has saved me at least one hour every week in maintaining this website. At last year’s rstudio::conf, an American lady talked to me in fluent Mandarin. I was so very impressed, but didn’t remember her name, which had been a shame to me. Luckily, she came to this year’s conference again. The first thing I did when I found her was to look at her badge and made sure I remembered the name, Amanda Johnson. However, I made the same mistake two days later when another lady came to me and told me she could also speak and read Chinese. It is kind of embarrassing for me to bend my neck to look at other people’s badges while talking. Anyway, she asked me for permission to correct other people’s pronunciation of my name. I was so touched! People were so kind and humble at this conference. Ian Lyttle was still carrying his notebook with him this year. The list of amazing people I met could go on and on, but I’m just going to stop here. How do you pronounce it? An extremely common topic I heard from all conversations was how to pronounce the name of a package or a certain term. For example, the most frequently asked question about the xaringan package is its pronunciation. Well, I have to make an official announcement that there is no official pronunciation of xaringan—just pronounce it in whatever way you like. If you are really curious about its authentic pronunciation, you can learn it from the video (at 01:04) on the Sharingan page of the Naruto wiki, or ask a Japanese friend to teach you. Similar examples include GGally (GG-ally or G-Galy), reprex (re-prex as in “reproduce” or rep-rex as in “replicate”), and memor (like mem-er or memo-R). Human names can be difficult to pronounce, too (e.g., my last name). The day before I gave my talk on pagedown, I asked Christophe, a native French, to record the pronunciation of the name “Romain Lesur” on my phone, and practiced it quite a few times in my room, so I could hopefully make my pronunciation of my collaborator’s name close enough in my talk (I have never met or talked to Romain in person). At a lunch, one person mentioned the “sword” sound in the beepr package, and I proudly told her that it was largely due to my useR! 2014 talk. Then we talked about the difficulties in the pronunciation of package and human names. I suggested that we record the authentic pronunciations and send pull requests to beepr, so that, for example, beepr::beep(12) tells us the pronunciation of “xaringan”, and beepr::beep(13) is “Yihui Xie”, etc. Would that be a good idea? Some of my experience in doing presentations I asked Hiroaki if he also had a talk at the conference, and he said he was concerned about his English language. Although I also struggle with English, I’m rarely worried about my language in presentations, because I’m sure native speakers will pretty much understand it regardless of all grammar or pronunciation problems. The requirement for English is much lower in a presentation than in a conversation, because a presentation is primarily a solo activity: you just keep talking on the stage. Given that rstudio::conf is a super friendly conference, presenters who are not native English speakers could have more confidence in themselves. With the observation of Hiroaki’s concern, I feel that perhaps we should offer some help to non-native speakers with their language if they prefer. I don’t know how many people decided not to give a talk because of language problems. In fact, non-native speakers have a special advantage. That is, idioms and jokes that are only familiar and popular to native speakers will sound particularly funny when said by a non-native speaker, because it is totally unexpected to them that you know such a joke or idiom. For example, someone (I believe it was an American) at the conference told me “your packages are very 666” (pronounced roughly as “leo-leo-leo” in Chinese). I guess no one knows what “666” means in today’s Chinese cyber culture (awesome/neat/slick) unless you are a young Chinese, so I had a good laugh when 666 was said from an American’s mouth. He told me his Chinese friend taught him this, and apparently it was very effective. Many people feel nervous on the stage. I’m rarely nervous there, but I do feel a little nervous in the few minutes before I walk onto the stage. My heartbeat quickens, too. That is very normal. I don’t feel nervous while I give the talk because I’m usually extremely focused on my talk. I wouldn’t notice it even if you pull an elephant into the room and walk it around while I’m giving the talk. FWIW, I failed the selective attention test the first time I saw it (I completely overlooked that animal). At the useR! 2014 conference in LA, I told Kevin Ushey that the more people in the room, the more comfortable I would be to give my talk. He was surprised. To some degree, this is similar to “one death is a tragedy, and a million deaths is a statistic.” When there are only a few people listening to your talk, you may feel the stare. When there are a thousand people in the audience, it really doesn’t matter how an individual reacts to your talk, so you should just shift your focus from the audience to your talk. And your talk may not be as important as you thought… One of the symptoms of an approaching nervous breakdown is the belief that one’s work is terribly important. — Bertrand Russell There is a special bonus of a large audience: jokes will work much better. Even mild jokes will make a fair number of people laugh. In all of my talks with a large audience, there are almost always a few people who laugh out so hard as if I paid them to laugh. I’m good at creating strange and unexpected associations among seemingly unrelated things (such as rmarkdown and the government shutdown), which often creates unexpected jokes. If anyone has a presentation that needs some flavor, I’ll be happy to help. Actually, if you think more about your best jokes coming up in the talk, it will also help you relax on the stage. Of course, being funny is not the goal. There are many excellent talks that don’t sound funny at all. It feels satisfactory when the audience laugh out loud, but we need to keep in mind that the means is not the goal. I have heard negative feedback on at least one of my talks, and that person thought the talk didn’t have much content, despite of the loud laughter. Perhaps I overdid it. I certainly want people to laugh and remember, instead of laughing and forgetting. BTW, no matter how much you love the dark theme of your editor, switch to a bright theme (and increase the font size) when you show live code demos. Where do you get ideas for your next R package? I was asked a few times how I found ideas for my new packages. First of all, I only work on one package each year in recent years, which has made the decision a little bit easier. Once I decide what to work on, I can ignore most of the news throughout the year. The amount of work that could be done is always much bigger than what we canactually do. You may need a long-term dream (like mine) to be able to focus. I read the Hacker Newsletter regularly, although I feel most of the items in each newsletter are not relevant or useful to me. I learned Gitbook, remark.js, Hugo, and ReLaXed from there, which in turn gave birth to bookdown, xaringan, blogdown, and pagedown, respectively. That means I find one thing or two in the newsletter directly relevant to my new R packages every year, which is actually enough. My other source of inspiration is Twitter. The pagedown package was finally born mainly because of one of Romain’s tweets about Paged.js. Even though I was excited about ReLaXed, I really didn’t want to introduce a Node package as the dependency of an R package. I saw a much brighter future from Romain’s tweet. More importantly, I felt the shared belief between him and me, so I reached out to him and we started to work on pagedown. My personal favorite talks There were three parallel sessions, so I only attended 1/3 of the talks. For those I attended, I especially loved these ones: Joe Cheng, Shiny in production Kara Woo, Box plots: A case study in debugging and perseverance Karl Broman, R/qtl2: Rewrite of a very old R package David Robinson, The unreasonable effectiveness of public work Kara’s talk showed an inspiring and detailed example of how to fix a bug in a famous (if not the most famous) R package. The R community needs more contributors like her. I love Karl’s special humor. Sometimes I cannot even tell if it is humor or he is just nervous at the podium, because he often appears to be speechless (and emotionless at the same time). I asked him later, and it seemed he was just speechless at the ridiculous examples in his talk. I thought he needed some encouragement at the podium (come on, Karl, you can do it). Anyway, there was a lady sitting in front me who laughed so loud and often, which made Karl’s talk even more amusing. Dave gave the closing keynote, and I agree with everything he said (definitely not because he mentioned me twice in his talk). Yes, publicize your work. Jared Lander’s annual feature requests I meet Jared Lander roughly annually. Each time he would make certain requests to me. For example, the bookdown package was an response to his request in 2014 when we met at the Strata conference. This year he wanted self-contained xaringan slides. This is a tricky issue because Markdown is not processed through Pandoc, but I’ll see what I can do. The next request was a talk at the New York R conference. I absolutely love this conference, but I’m still waiting for my two little kids to grow (I cannot offer them six meals a day to let them grow twice as fast). If any R Markdown ninja volunteers to go, I’ll be happy to help create a Yihui-style talk. A random idea: turn your Dropbox folder into a public website through plumber and rdrop2 On the first day of our R Markdown workshop, Hao told me my slides were no longer accessible, which scared me. I usually serve my slides through Updog.co. Unfortunately the service was down right before the workshop, but was recovered later that day. I came up with an idea of an alternative implementation of Updog.co after this incidence, and will leave it as an exercise to those who are interested: In R, we have the rdrop2 package to access a Dropbox folder. Then we also have the plumber package to build simple web APIs. With these two pieces, it is enough to turn a private Dropbox folder into a public website. What the API does is simply read static files and return their content (i.e., a static file server). If you host the plumber API on a public server, you will be able to enjoy a similar service as Updog. The video recording of my talk RStudio is currently uploading all conference videos. If you are interested, my talk is already there: Many other people have written blog posts about this conference (again, see Karl’s repo). I have read most of them, and they are all beautifully written (I’m particularly impressed by Brooke Watson’s hand-drawing skills). I feel very glad and proud to learn that people found this conference super friendly, inclusive, welcoming, and helpful. Many thanks to those who made this conference such a positive experience, and looking forward to rstudio::conf(2020) in San Francisco! "},"Sis/ml信息熵.html":{"url":"Sis/ml信息熵.html","title":"信息熵","keywords":"","body":""},"Sis/ml神经网络.html":{"url":"Sis/ml神经网络.html","title":"模拟神经网络","keywords":"","body":""},"Sis/ml03_supervised_learning.html":{"url":"Sis/ml03_supervised_learning.html","title":"监督学习和无监督学习","keywords":"","body":"监督学习和无监督学习 "},"Sis/ml03_sl_linear_regression.html":{"url":"Sis/ml03_sl_linear_regression.html","title":"回归 线性回归","keywords":"","body":"线性回归---回归 线性回归 linear regression属于线性模型的一种，广义线性模型主要包括： 1.回归问题 回归模型是表示输入变量到输出变量之间映射的函数， 回归问题的学习等价于函数拟合： 使用一条函数曲线 使其很好的拟合已知函数且很好的预测未知数据。 2.线性回归公式 将截距单独拎出来。 将截距算进向量相乘的结果中。x 表示m行（n+1）列的矩阵，m代表样本数量，n表示数据集中的维度，1表示增加的一列（数值都为1）。 3.最小化损失函数 一元线性回归中，对于每一个样本，ε 表示真实值和预测值之间的差异： 一元线性回归的损失函数loss function （MSE: mean square error）(最小二乘法公式)： MSE 只与正态分布和似然估计有关，换做回归以外其他机器学习算法，损失函数也可以是MSE。 【目标】使ε差异在总体上尽可能的小，求出误差最小时的w、b值。 【问题】为什么损失函数是计算平方和？ 3.1 正态分布normally distributed 每个样本的实际值 = 预测值 + 误差。 假设所有样本都是独立同分布的，假设数据服从**正态分布，实际值在预测曲线上下震荡，根据中心极限定理，误差值服从**正态分布（也服从高斯分布）。误差的均值是0，所以不能用误差的简单求和来评估损失的大小。 同分布： 做特征工程前后，数据的分布情况是一致的，例如之前是正态分布，特征工程之后也是正态分布。深度学习中，每一层的数据的分布也是一致的。 3.2 概率密度函数 正态分布的概率密度函数如下： （在数学中， 连续型随机变量的概率密度函数是一个描述这个随机变量的输出值， 在某个确定的取值点附近的可能性的函数。 而随机变量的取值落在某个区域之内的概率则为概率密度函数在这个区域上的积分。） 由于误差ε符合正态分布，将其代入概率密度函数： 3.3 似然函数 最大似然估计（找出一组参数，使模型产生出观测数据的概率最大）思想下的似然函数是关于统计模型参数的函数。 关于参数θ的似然函数L(θ|x)等于给定参数θ后变量X的概率： L(θ|x)=P(X=x|θ)。 由于误差之间是相互独立的，整体样本的误差输出取值的可能性如下（即目标函数）： 3.4 自然对数 为了便于将上述公式展开化解，对两边分别取以e为底的自然对数： （由于） 让似然函数代表的概率越大越好，就代表误差取值在正态分布中更加集中；所以就要使 J(w)越小越好，即需要求解 J(w) 最小时的 w值 和 b值。 3.5.1 偏导与解析解(正规方程) 一元线性回归： 将w，b看为未知变量，x，y看为常数。多个变量情况下求J(w)极值，所以要对 w、b求偏导。 复合函数的求导： 多元线性回归： theta值有多个，不可能逐个对theta求偏导，所以使用矩阵：m行 * (n+1)列。 将误差函数转化为有确定解的代数方程组，从而可求解出这些未知参数，而不用迭代的方法，这就是正规方程(normal equations)法。得到的参数的解就是解析解。 3.5.2 梯度下降 为什么用梯度？ 对于n维矩阵，以上的解析解的复杂度是O(n)的三次方，所以我们使用梯度下降（gradient descent）的方法来求解局部最优解；因为线性回归损失函数是一个凸函数，此时使用梯度下降求解得到的其实是全局最小值。 凸函数的判定 什么是梯度？ 对点x0的导数反映了函数在点x0处的瞬时变化速率。推广到多维函数中，就有了梯度的概念，梯度是一个向量组合，向量是有方向的，反映了多维图形中变化速率最快的方向（下坡最快）。 在微积分里面，对多元函数的参数求∂偏导数，把求得的各个参数的偏导数以向量的形式写出来，就是梯度。 比如函数f(x,y), 分别对x,y求偏导数，求得的梯度向量就是(∂f/∂x, ∂f/∂y)T,简称grad f(x,y)或者▽f(x,y)。 对于在点(x0,y0)的具体梯度向量就是(∂f/∂x0, ∂f/∂y0)T.或者▽f(x0,y0)。 什么是梯度下降？ 我们把要最小化或最大化的函数称为 目标函数（objective function）或 准则（criterion）。当我们对其进行最小化时，我们也把它称为 代价函数（cost function）、损失函数（loss function）或 误差函数（error function）。 通常使用一个上标 ∗ 表示最小化或最大化函数的 x 值。如我们记 x**∗ =arg min f(x)**。 导数 f ′(x) 代表 f(x) 在点 x 处的斜率。换句话说，它表明如何缩放输入的小变化才能在输出获得相应的变化： f(x + ϵ) ≈ f(x) + ϵf ′(x)。 导数对于最小化一个函数很有用，因为它告诉我们如何更改 x 来略微地改善 y。例如，我们知道对于足够小的 ϵ 来说， f(x - ϵsign(f ′(x))) 是比 f(x) 小的，我们可以将 x 往导数的反方向移动一小步来减小 f(x)。这种技术被称为 梯度下降（gradient descent）。 驻点 f ′(x) = 0 的点称为 临界点**（critical point）或 驻点（stationary point）**。 有些临界点既不是最小点也不是最大点，这些点被称为 鞍点（saddle point）。 使 f(x) 取得绝对的最小值（相对所有其他值）的点是 全局最小点（global minimum）。 函数可能只有一个全局最小点或存在多个全局最小点，还可能存在不是全局最优的局部极小点（local minimum） 。 梯度的意义？ 从几何意义上讲，就是函数变化增加最快的地方。 具体来说，对于函数f(x,y),在点(x0,y0)，沿着梯度向量的方向就是(∂f/∂x0, ∂f/∂y0)T的方向是f(x,y)增加最快的地方；或者说，更加容易找到函数的最大值。 反过来说，沿着梯度向量相反的方向，也就是 -(∂f/∂x0, ∂f/∂y0)T的方向，梯度减少最快，也就是更加容易找到函数的最小值。 梯度思想的三要素 梯度法思想的三要素：出发点、下降方向、下降步长。 alpha表示学习率（learning rate），表示梯度下降的步长。例如： 求解梯度 4.批量梯度下降BGD 每一次的参数更新都用到了所有的训练数据， 所以BGD算法会非常耗时。 5.随机梯度下降SGD Stochastic Gradient Descent SDG求出的解是可用的解，即符合定义的误差阈值内的解，但这个解可能不够精准。 SGD伴随的一个问题是噪音较BGD要多， 使得SGD并不是每次迭代都向着整体最优化方向。 6.小批量梯度下降MBGD Mini-Batch Gradient Descent 解决BGD和SGD的缺点， 使得算法的训练过程比较快， 而且也要保证最终参数训练的准确率。 不同问题设置的batch是不一样的。 "},"Sis/ml03_sl_logistic_regression.html":{"url":"Sis/ml03_sl_logistic_regression.html","title":"分类 逻辑回归","keywords":"","body":"逻辑回归---分类 1.问题引出 分类问题中，线性模型会遇到对数据无法分类的问题，如何解决？如下： 线性模型的y取值范围为：，对于二分类问题（多分类问题也可以转为为二分类），可以从以下三个思路来思考解决线性模型无法分类的问题： 弃用线性模型，改为非线性模型； 将线性模型映射到高维空间，例如，用超平面来分类； 使线性模型的预测值逼近真实值的衍生物，例如，，如果可以将 z 值转为（0,1）范围内的预测值，就完成了分类任务。类似单位阶跃函数（unit-step function）: （单位阶跃函数不连续） 广义线性模型(generalized linear model) 称为联系函数（link function）。根据以上思路，假如能找到一个单调可微函数，可以将线性回归模型的预测值和分类问题中的真实标记y联系起来，就相当于用线性回归模型解决了二分类问题。 对数几率函数（logistic function）就是满足要求的一个单调可微函数。 对数几率函数 逻辑回归的意译为对数（logit）几率回归。根据以上思路，用线性回归模型的预测值去逼近真实标记的衍生物，即真实标记的对数几率（log odds 或 logit），几率表示样本为正例的可能性与反例的可能性的比值，几率取对数就得到对数几率： 逻辑变换 将对数几率函数代入广义线性模型，得到； 用预测值毕竟真实标记的对数几率，得到，即。 通过逻辑变换，将线性回归的预测值从，缩放到了(0,1)，代表对分类类别的概率预测。 逻辑回归也是广义线性模型的一种。 2.逻辑回归公式 ，在坐标轴上表现如下： 2.1 损失函数 确定了一组w 或 theta 就确定了 z，确定了z 就确定了 g(z) 的输出, 那么g(z) 也可以写成 g(w,x)。 根据最大似然估计，，进而表示如下： 为了模型预测有最高的准确率，即找到一组theta值，使似然估计的L(theta)有最大值。为了将乘积展开，等式两边取对数，而且对数函数最大时（单调递增），L(theta)也最大。 损失函数： 以上损失函数又叫交叉熵损失函数（Cross Entropy Loss）。 2.2 交叉熵 熵 (entropy) 这一词最初来源于热力学。1948年，克劳德·爱尔伍德·香农将热力学中的熵引入信息论，所以也被称为香农熵 (Shannon entropy)，信息熵 (information entropy)。熵代表的是随机变量或整个系统的不确定性，熵越大，随机变量或系统的不确定性就越大。 一条信息的信息量大小和它的不确定性有直接的关系。可以认为，信息量的度量就等于不确定性的多少，不确定的多少可以用概率分布来表达，信息的量度应该依赖于概率分布 p(x)。 信息量 如果有两个不相关的事件 x 和 y，那么两个事件同时发生时获得的信息量应该等于观察到事件各自发生时获得的信息之和：，两个事件是彼此独立的： I(x) 也被称为随机变量 xx 的自信息 (self-information)，描述的是随机变量的某个事件发生所带来的信息量。 熵 H(X) 被称为随机变量 x 的熵,表示随机变量不确定的度量，是对所有可能发生的事件产生的信息量的期望。从公式可得，随机变量的取值个数越多，状态数也就越多，信息熵就越大，混乱程度就越大。当随机分布为均匀分布时，熵最大，且 0≤H(X)≤logn。 交叉熵 现在有关于样本集的两个概率分布 p(x) 和 q(x)，其中 p(x) 为真实分布， q(x) 非真实分布。 用真实分布 p(x)来衡量识别别一个样本所需要编码长度的期望（平均编码长度）为: 使用非真实分布 q(x)来表示来自真实分布 p(x) 的平均编码长度，则是： 此时就将H(p,q) 称之为交叉熵。交叉熵用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出成本的大小。 交叉的字面意思在于：真实分布与非真实分布的交叉。给定一个方案, 越优的策略, 最终的交叉熵越低，具有最低的交叉熵的策略就是最优化策略。 交叉熵用于计算“学习模型的分布”和“训练数据的分布”之间的不同，当交叉熵最低（等于训练数据分布的熵）时，就相当于学到了最好的模型。 2.3 梯度下降 通过梯度下降，最小化损失函数：（以下的theta就是 w，代表参数） 3.多分类问题 多分类问题的解决思路： 将n分类转成n个2分类 ，训练出n个逻辑回归的模型 ； 用softmax处理多分类 3.1 softmax 预测函数： 为了预测类别，需要确定的是： 损失函数： 梯度下降： "},"Sis/ml03_sl_svm.html":{"url":"Sis/ml03_sl_svm.html","title":"分类 SVM","keywords":"","body":"SVM---分类 1.函数最优化问题 1.1 无约束条件的最优化问题 1.2 有约束条件的最优化问题 以下约束条件中没有考虑 >0 的情况，因为可以由小于等于0反推出来。 将以上最优化问题命名为原始（最优化）问题。 凸优化问题：对于上述有约束条件的最优化问题，目标函数 f(x) 和约束函数 都是R上连续可微的凸函数，是R上的仿射函数（满足） 1.3 求解最优化问题 方法：梯度下降、L-BFGS、IIS等 1.4 拉格朗日函数 拉格朗日函数是将原始问题的f(x)和约束条件进行整合， 使有约束条件的最优化问题>>>>>转为>>>>>无约束条件的最优化问题。 使原始问题的一次优化问题>>>>>转为>>>>>极小极大的二次优化问题。 在约束最优化问题中，常利用拉格朗日对偶性（Lagrange duality）将原始问题转换为对偶问题，通过求解对偶问题得到原始问题的解。 拉格朗日乘子（Lagrange multiplier）: 拉格朗日乘子向量： 拉格朗日函数的特性 极小极大 由拉格朗日函数的特性可知，当x满足原始问题约束时， 就是原始问题的f(x)，此时进行极小化就等同于对原始（最优化）问题进行极小化，解是相同的，即： 对偶问题 被称为拉格朗日函数的极大极小问题，也被称为原始问题的对偶问题。 定义 为对偶最优化问题的最优解，当 f(x)和为凸函数，是仿射函数时，有： ，其中的约束条件为KKT条件： 2.Support Vector Machine SVM：线性的分类（二分类）算法。 基本思想：求解能够正确划分训练数据集，且几何间隔最大的分离超平面。间隔最大化，意味着以充分大的确信度对训练数据进行分类。 支持向量机(Support Vector Machine)是Cortes和Vapnik于1995年首先提出的，它在解决小样本、非线性及高维模式识别中表现出许多特有的优势。 2.1 线性可分SVM 线性可分性 给定一个数据集，如果存在某个超平面，满足： 将数据集的正实例点和负实例点完全正确的划分到超平面的两侧； 对所有的实例，都有；对所有的实例，都有。 则称以上数据集是线性可分（linearly separable）的。 模型判别式： ，是线性的公式，本质是在高维空间找到一个超平面来分隔数据。 通常这样用于分隔的超平面有很多，哪一个最好？ 最好的超平面： 完美的分类正负例 距离最近的点越远越好（对点位置变动的容忍度大），即硬间隔越大越好。（最大间隔法） （根据以上两点确定的超平面，求出y=0时的w值和b值。） 几何距离和函数距离 函数距离（functional margin）可以表示分类的正确性和分类预测的确信度。 最优化问题 根据距离公式，可以将最好的超平面的定义转换为函数的最优化问题： 如果将 w 和 b 等比例缩放为 λw 和 λb，函数间隔变成 λγ'，函数间隔的改变对不等式约束没有影响，对目标函数的优化也没有影响。于是，为了方便求解，直接令 γ' = 1，改变上述最优化问题，得到： 进一步根据上述最优化问题，构建拉格朗日函数： 根据对偶函数，先求极小值，拉格朗日函数分别对 w 和 b 求导，求出 w 和 b 各自与 α 的关系。 根据以上推导，求导得出： 将求导结果代入原来的函数： 进一步转换对偶问题的优化问题为： 通常使用SMO算法（序列最小最优化算法）进行求解，可以求得一组 α*使得函数最优化。求解之后，α*成为已知数，根据KKT条件，再求出 w*，b* . 支持向量 由上述根据 α* 推导 w*，b* 的过程可知，时，，此时对应的样本点 的实例就是支持向量，支持向量一定是在间隔边界上。 2.2线性SVM 线性不可分 为了得到最好的分隔超平面，满足的条件有： （满足约束条件时）可以把正负例完美分开 找到间隔最大的点（函数优化问题） 对于线性不可分问题，会有噪声点，不满足线性可分SVM中的约束条件，为了放松约束条件，而引入松弛变量。 ξ代表异常点嵌入间隔面的深度,我们要在能选出符合约束条件的最好的w和b的同时,让嵌入间隔面的总深度越小越好。 最优化问题 线性SVM的原始问题（凸二次规划问题）如下： 分类决策函数 求出原始问题的最优解，代入，即得到分类决策函数。 分离超平面为 构建拉格朗日函数 求解 用SMO算法求出 α*. 支持向量 SVM模型判别式的另一种表示： 结论：每一次计算判别函数的结果时，需要求得判别点和所有训练集样本点的内积。 2.3非线性SVM SVM升维 为了处理线性不可分问题，可以引入升维，即把原始的 x 映射到更高维度的空间： 【问题】升维之后，再做向量的内积，会出现维度爆炸。 【解决】引入核函数。思路：不具体计算向量的内积，而是直接定义的结果。 核函数 2.4 SVM算法流程总结 选择核函数及对应的超参数； 选择惩罚系数C； 构造最优化问题； 利用SMO算法求出一组 α* ； 根据 α*计算w* 根据α*找到全部的支持向量，计算每个支持向量对应的 对求均值，得到 b* 得到判别函数和超平面。 【参考】 《统计学习方法》第二版 李航著； https://blog.csdn.net/u014540876/article/details/80172623 "},"Sis/ml03_sl_knn.html":{"url":"Sis/ml03_sl_knn.html","title":"回归/分类 KNN","keywords":"","body":"KNN---回归/分类 1.图解KNN knn的变种算法：KD树、球树。（KD树， 球树之类的模型建立需要大量的内存） 2.K值的选择 对于k值的选择， 没有一个固定的经验， 一般根据样本的分布， 选择一个较小的值， 可以通过交叉验证选择一个合适的k值。 选择较小的k值， 就相当于用较小的领域中的训练实例进行预测， 训练误差会减小， 容易发生过拟合。 选择较大的k值， 就相当于用较大领域中的训练实例进行预测， 其优点是可以减少泛化误差， 但缺点是训练误差会增大。 "},"Sis/ml03_sl_decision_tree.html":{"url":"Sis/ml03_sl_decision_tree.html","title":"决策树","keywords":"","body":""},"Sis/ml03_sl_bayes.html":{"url":"Sis/ml03_sl_bayes.html","title":"贝叶斯","keywords":"","body":"贝叶斯Bayes 贝叶斯：统计学statistics概念，英国数学家Reverend Thomas Bayes发明。 贝叶斯法则 Bayes rule 在已知事件B发生的条件下，A的概率。公式的似然概率中包含了概率的反向推导。 举例： A： 患者得癌症的概率。 B：检测结果。 贝叶斯网络 Bayes networks 将贝叶斯法则画图表示，得到贝叶斯网络： 要定义贝叶斯网络需要3个参数：1一个用来指定P(A)，2个分别用来指定条件概率。 "},"Sis/ml03_sl_xgboost.html":{"url":"Sis/ml03_sl_xgboost.html","title":"XGBoost","keywords":"","body":"XGBoost 1.GBDT "},"Sis/mlkmeans.html":{"url":"Sis/mlkmeans.html","title":"K-Means","keywords":"","body":"K-means：理论 一、K-均值聚类（K-means）概述 1. 聚类 “类”指的是具有相似性的集合。聚类是指将数据集划分为若干类，使得类内之间的数据最为相似，各类之间的数据相似度差别尽可能大。聚类分析就是以相似性为基础，对数据集进行聚类划分，属于无监督学习。 2. 无监督学习和监督学习 和KNN所不同，K-均值聚类属于无监督学习。那么监督学习和无监督学习的区别在哪儿呢？监督学习知道从对象（数据）中学习什么，而无监督学习无需知道所要搜寻的目标，它是根据算法得到数据的共同特征。比如用分类和聚类来说，分类事先就知道所要得到的类别，而聚类则不一样，只是以相似度为基础，将对象分得不同的簇。 3. K-means k-means算法是一种简单的迭代型聚类算法，采用距离作为相似性指标，从而发现给定数据集中的K个类，且每个类的中心是根据类中所有值的均值得到，每个类用聚类中心来描述。对于给定的一个包含n个d维数据点的数据集X以及要分得的类别K,选取欧式距离作为相似度指标，聚类目标是使得各类的聚类平方和最小，即最小化： J=∑k=1k∑i=1n∥xi−uk∥2 J=\\sum_{k=1}^{k} \\sum_{i=1}^{n}\\left\\|x_{i}-u_{k}\\right\\|^{2} J=​k=1​∑​k​​​i=1​∑​n​​∥x​i​​−u​k​​∥​2​​ 结合最小二乘法和拉格朗日原理，聚类中心为对应类别中各数据点的平均值，同时为了使得算法收敛，在迭代过程中，应使最终的聚类中心尽可能的不变。 4. 算法流程 K-means是一个反复迭代的过程，算法分为四个步骤：1） 选取数据空间中的K个对象作为初始中心，每个对象代表一个聚类中心；2） 对于样本中的数据对象，根据它们与这些聚类中心的欧氏距离，按距离最近的准则将它们分到距离它们最近的聚类中心（最相似）所对应的类；3） 更新聚类中心：将每个类别中所有对象所对应的均值作为该类别的聚类中心，计算目标函数的值；4） 判断聚类中心和目标函数的值是否发生改变，若不变，则输出结果，若改变，则返回2）。 用以下例子加以说明： 图1：给定一个数据集；图2：根据K = 5初始化聚类中心，保证　聚类中心处于数据空间内；图3：根据计算类内对象和聚类中心之间的相似度指标，将数据进行划分；图4：将类内之间数据的均值作为聚类中心，更新聚类中心。最后判断算法结束与否即可，目的是为了保证算法的收敛。 二、Python 实现（过程忽略） 总结：在这次程序的调试中，其实出现的问题还是蛮多的，相似度指标依旧选用的是欧氏距离。在之前，一直是按照公式直接计算的，可欧氏距离其实就是2范数啊，2范数属于酉不变范数，因此矩阵的2范数就是矩阵的最大奇异值，在求解过程中可以直接采用norm函数简化。 模型检验 上图中的结果可以清晰的看到算法具有一定的聚类效果，要进一步验证的话，可以采取MCR或者NMI和ARI这些常用的准则进行衡量聚类结果的优劣，在此我选取MCR进行验证，代码如下： %% 采用MCR判定聚类效果 B = class(:,4); B = reshape(B,1,row); A = [ones(1,100),2 * ones(1,100),3 *ones(1,100),4 * ones(1,100)]; sum = 0; for i = 1:row if ( A(1,i) ~= B(1,i)) sum = sum + 1; end end MCR = sum / row; fprintf('MCR = %d\\n',MCR); 多次计算平均求得的MCR= 0.53,表明误分率还是蛮大的，聚类效果并不是很理想，究其原因：虽然算法收敛，但算法只是收敛到了局部最小值，而并非全局最小值，所以可以引入二分K-均值对算法进行优化。除此之外，FCM算法在一定程度上也是对算法的一个优化吧。 原文：https://www.cnblogs.com/ybjourney/p/4714870.html "},"Sis/ml03_ul_em.html":{"url":"Sis/ml03_ul_em.html","title":"EM","keywords":"","body":""},"Sis/ml03_ul_pca.html":{"url":"Sis/ml03_ul_pca.html","title":"PCA","keywords":"","body":""},"Sis/vizAwesome_dataviz.html":{"url":"Sis/vizAwesome_dataviz.html","title":"Awesome dataviz","keywords":"","body":""},"Sis/vizQGIS.html":{"url":"Sis/vizQGIS.html","title":"QGIS","keywords":"","body":"用Python做 # "},"Sis/sqlHive时间函数.html":{"url":"Sis/sqlHive时间函数.html","title":"Hive 时间函数","keywords":"","body":""},"Sis/shell.html":{"url":"Sis/shell.html","title":"使用 Shell 发邮件","keywords":"","body":"shell 基本知识和规范 shell check shell check 可以检测语法问题和 bad code。有两种使用方式： 1.网页版：https://www.shellcheck.net/ 2.终端：shellcheck test.sh 变量规范 "},"sis/leecode185.html":{"url":"sis/leecode185.html","title":"185. 部门工资前三高的员工","keywords":"","body":"185. 部门工资前三高的员工 Employee 表包含所有员工信息，每个员工有其对应的 Id, salary 和 department Id 。 Department 表包含公司所有部门的信息。 编写一个 SQL 查询，找出每个部门工资前三高的员工。例如，根据上述给定的表格，查询结果应返回： 解答: SELECT Department, Employee, Salary FROM ( SELECT Department,Employee,Salary, @rowNum :=IF(@LastD = t.Department,@rowNum + ( @lastS <> t.Salary ),1 ) AS seq, @lastD := t.Department, @lastS := t.Salary FROM (SELECT d.NAME Department,e.NAME Employee,Salary FROM Employee e,Department d WHERE e.DepartmentId = d.Id ORDER BY d.NAME,Salary DESC ) t, (SELECT @lastD:= -1,@lastS:= -1,@rowNum:= 0 ) AS init ) AS t2 WHERE t2.seq "},"sis/leecode601.html":{"url":"sis/leecode601.html","title":"601. 体育馆的人流量","keywords":"","body":"601. 体育馆的人流量 X 市建了一个新的体育馆，每日人流量信息被记录在这三列信息中：序号 (id)、日期 (date)、 人流量(people)。 请编写一个查询语句，找出高峰期时段，要求连续三天及以上，并且每天人流量均不少于100。 例如，表 stadium： 对于上面的示例数据，输出为： Note:每天只有一行记录，日期随着 id 的增加而增加。 答案select distinct a.* from stadium a,stadium b,stadium c where a.people >= 100 and b.people >= 100 and c.people >= 100 and ( (a.id+1 = b.id and b.id+1 = c.id) or (a.id-1 = b.id and a.id+1 = c.id) or (a.id-1 = c.id and a.id+1 = b.id) or (a.id-2 = b.id and a.id-1 = c.id) or (a.id-1 = b.id and a.id-2 = c.id) ) order by a.id 笔记 高票答案与我的逻辑一样，但如果需要连续 n 天，没办法灵活改动。 有别人的写法： SELECT id, `date`, people FROM ( SELECT id, `date`, people, @m := IF(k >= 3 OR (@n - k >= 0 AND k > 0), 1, 0) AS t, @n := IF(k = 3, 3, @n - k) AS _2, k FROM ( SELECT id, `date`, people, @i := IF(people >= 100, 1, 0) AS _, @j := IF(@i = 1, @j + 1, 0) AS k FROM stadium , (SELECT @i:=0, @j:=0) __a ORDER BY id ) t , (SELECT @m:=0, @n:=0) __a ORDER BY id DESC ) a WHERE t = 1 ORDER BY id 可以解决十几天连续超过100人的问题； 引入单个变量； 代码可读性和可迁移性也还行 select stadium.* from stadium inner join ( select id-rownum as diff ,group_concat(id) as idlist from ( select @rownum:=@rownum+1 as rownum ,id from stadium,(select @rownum :=0) t where people>=100 )t group by id-rownum having length(group_concat(id))-length(replace(group_concat(id),',',''))>=2 #表示至少出现三个id )t on find_in_set(stadium.id,t.idlist) "},"sis/leecode615.html":{"url":"sis/leecode615.html","title":"615. ","keywords":"","body":"615. Average Salary: Departments VS Company 类型：困难 题目 Given two tables as below, write a query to display the comparison result (higher/lower/same) of the average salary of employees in a department to the company's average salary. drop table salary; Create table salary(Id int,employee_id int,amount int,pay_date date); insert into salary values(1,1,9000,'2017-03-31'); insert into salary values(2,2,6000,'2017-03-31'); insert into salary values(3,3,10000,'2017-03-31'); insert into salary values(4,1,7000,'2017-02-28'); insert into salary values(5,2,6000,'2017-02-28'); insert into salary values(6,3,8000,'2017-02-28'); drop table employee Create table employee(Id int,department_id int); insert into employee values(1,1); insert into employee values(2,2); insert into employee values(3,2); Table: salary | id | employee_id | amount | pay_date | |----|-------------|--------|------------| | 1 | 1 | 9000 | 2017-03-31 | | 2 | 2 | 6000 | 2017-03-31 | | 3 | 3 | 10000 | 2017-03-31 | | 4 | 1 | 7000 | 2017-02-28 | | 5 | 2 | 6000 | 2017-02-28 | | 6 | 3 | 8000 | 2017-02-28 | The employee_id column refers to the employee_id in the following table employee. | employee_id | department_id | |-------------|---------------| | 1 | 1 | | 2 | 2 | | 3 | 2 | So for the sample data above, the result is: | pay_month | department_id | comparison | |-----------|---------------|-------------| | 2017-03 | 1 | higher | | 2017-03 | 2 | lower | | 2017-02 | 1 | same | | 2017-02 | 2 | same | Explanation In March, the company's average salary is (9000+6000+10000)/3 = 8333.33... The average salary for department '1' is 9000, which is the salary of employee_id '1' since there is only one employee in this department. So the comparison result is 'higher' since 9000 > 8333.33 obviously. The average salary of department '2' is (6000 + 10000)/2 = 8000, which is the average of employee_id '2' and '3'. So the comparison result is 'lower' since 8000 With he same formula for the average salary comparison in February, the result is 'same' since both the department '1' and '2' have the same average salary with the company, which is 7000. 大致内容：看看一个部门的平均工资，跟公司总体相比，是更高还是更低。"},"sis/leecode618.html":{"url":"sis/leecode618.html","title":"618. ","keywords":"","body":"618. Students Report By Geography 等级：困难 题目 drop table student create Table student (name varchar(25),continent varchar(25)); insert into student values('Jack','America') insert into student values('Pascal','Europe') insert into student values('Xi','Asia') insert into student values('Jane','America') A U.S graduate school has students from Asia, Europe and America. The students' location information are stored in table student as below. Pivot the continent column in this table so that each name is sorted alphabetically and displayed underneath its corresponding continent. The output headers should be America, Asia and Europe respectively. It is guaranteed that the student number from America is no less than either Asia or Europe. Follow-up: If it is unknown which continent has the most students, can you write a query to generate the student report? 大致意思是：旋转这张表，列变行，达成下面的效果。你并不知道有多少学生。 --Before | name | continent | |--------|-----------| | Jack | America | | Pascal | Europe | | Xi | Asia | | Jane | America | --After | America | Asia | Europe | |---------|------|--------| | Jack | Xi | Pascal | | Jane | | | 思路 按大洲分组，然后给给每个学生加上一个编号，跟 row_number() 的思路一样，然后再 FULL JOIN，大致形成这样一个表： 这就产生了一个问题，MySQL 中没有 row_number() 那么好用的开窗函数，怎么办？🙂 "},"sis/blog人大统计硕士笔记.html":{"url":"sis/blog人大统计硕士笔记.html","title":"人大统计硕士笔记","keywords":"","body":" 人大统计硕士笔记 本科的课程不够用，一直在自学统计学。苦于自己理论水平太差，2018年9月报考了人大统计学院的进修班，两年。 以下是一些记录： 报名 2019年9月报名，两年费用33000元。隔周上课，周六、日连续，上午9点-下午4点。 课程目录如下： 第一堂课 上课地点在人大明德楼，教授是*。 笔记 考试 *参加考试 拿到研究生学位 有没有用 课堂没什么用，全靠自学。 学位的作用，目前还不清楚。 统计学（大数据应用及数据分析方向）课程安排： 根据我院全日制研究生培养方案学分要求，在职研究生开设课程包括： 题 库 课 程 类别 课程名称 学分 课程介绍 必修课 中国特色社会主义理论与实践 2 政治理论课 必修课 高等统计学(数理统计学) 3 目的在于使学生在原基础上，理解数理统计的基本概念，熟悉抽样分布理论，掌握参数估计的理论与方法、统计假设检验的主要方法、统计决策理论与Bayes分析，以及统计计算方法。 必修课 统计思想综述 2 统计学的方法论课程。统计学科的定义、核心和边界，理论要点。各种方法的前提假设与应用边界条件。 必修课 抽样技术与方法 3 主要介绍古典概率抽样方法，利用辅助信息基于线性模型的估计，二重抽样，最优抽样设计，无回答和计量误差等。 非 题 库 课 程 必修课 专业外语（英语） 3 语言基础、国考科目 必修课 马克思主义与社会科学方法论 1 政治理论课 必修课 《资本论》选读 3 本课程要求学生必修。讨论马克思《资本论》的对象、方法、结构和基本理论以及对研究当代经济问题的指导意义。 必修课 多元统计分析 3 本课程的内容包括多元回归分析，判别分析，聚类分析，主成分分析，因子分析，典型相关分析，结构方程模型，对应分析等。 必修课 数据挖掘方法与应用 2 通过课程教学和专题讨论，掌握数据挖掘常用方法的基本原理和方法特点，并能够运用数据挖掘软件解决数据挖掘的实际问题。 必修课 定性数据研究方法 2 本课程主要讲授定性数据的搜集方法和对定性数据的分析方法；主要内容有凯利表的数据采集与分析，焦点组技术、深访技术、文本分析等方法；课程的教学目的是掌握定性数据的研究方法并能够与定量技术结合使用。 必修课 统计预测 2 本课程主要包含如下内容：平稳序列建模及预测，波动性建模，协整和误差修正模型，向量自回归模型及面板数据建模。 必修课 宏观经济统计分析 2 主要是讲述中国宏观经济统计分析的内容，集理论、问题、数据、方法于一体，案例加体系的课程。 必修课 经济统计研究 3 以国民经济核算为起点做内容扩展，培养运用统计手段进行宏观经济观察分析的能力。 选修课 统计诊断 2 涉及的主要内容：回归异常点分析、残差分析、回归影响分析、数据变换及诊断、广义影响分析、多元回归诊断、其他广义模型诊断、拟合欠佳检验、非参数蒙特卡罗检验、实例分析等等。 选修课 市场研究 2 通过案例分析展现市场研究过程的各个步骤，运用数据分析解决市场营销管理的决策问题。 前沿讲座 资本存量估算研究 针对中国的综合环境经济核算实施与建模研究 全球化背景下中国对外经济统计与计量分析 环境经济核算国际经验追踪及环境会计研究 中国信息服务业发展与影响研究 中国金融账户及其影响初探 全球化背景下对外贸易统计方法的改进 中国外资经济的环境效应分析 注：课程设置按当年最新培养方案及教学计划为准。 "},"sis/0.html":{"url":"sis/0.html","title":"201908 旧金山","keywords":"","body":"This is my personal homepage written in English (and in Markdown), a site mainly to record my study in Statistics and some other related topics. Some years ago when I read the book Statistics And Truth, I found the statements in its preface quite interesting: All knowledge is, in final analysis, history. All sciences are, in the abstract, mathematics. All judgements are, in their rationale, statistics. If you are curious about these sorts of judgments, you may be interested in some of my blogs. I also post articles on programming techniques, especially for the R language. This site is driven by Hugo. You can find the source code of this site in the GitHub repository. The theme is modified from Tranquilpeak. I also have a Chinese homepage. Please come here. "},"sis/blog加州伯克利东亚图书馆.html":{"url":"sis/blog加州伯克利东亚图书馆.html","title":"201909 加州大学伯克利分校东亚图书馆","keywords":"","body":"加州大学伯克利分校东亚图书馆 2018年7月18日，中美图书馆员学术交流项目的最后一个行程---参观加州大学伯克利分校图书馆。 一个月的时光，无论是视觉还是听觉，都积攒了大量有待消化吸收的信息。从一开始就明白，机会来之不易，唯有竭力去学习和感知。最后半天宝贵的时间，我们将参观伯克利分校的校园、主图书馆和东亚图书馆。 第一站斯塔尔东亚图书馆（C.V.Starr East Asian Library）在校园中心纪念大草坪的旁边，是一座具有东方特色的白色方形建筑。这就是著名的东亚图书馆，是美国第一个专门为东亚收藏而建的具有独立馆舍的图书馆。 图书馆通身都具有东方古典气息，依坡而建，一共三层，并不算大，给人的第一印象低调典雅。经过一个楼梯和天桥走廊，来到大门前，在这个天桥上面看风景是个绝佳的位置，对面就是主图书馆大楼。门旁一边是自动还书箱，另一边有一个供轮椅进出的按钮，不得不佩服他们的无障碍设施已经做到了社会的方方面面。进了大门，里面的台阶大多也是素色大理石，有些墙面也没有处理，保持一种朴素的状态。偶有几个明清的仿古家具点缀其中，靠窗一边的吊灯透着暖黄色的光，像一个个灯笼从天花板上垂下来，古香古色，仿佛置身于家乡。 这座新建成的东亚图书馆于２００８年３月正式开放，是全美三大东亚图书馆之一，收有东亚100万册纸质书，其中中国馆藏60万；它将以前的中国研究图书馆（CCSL）和东亚图书馆（EAL）的馆藏合二为一。 一个月的参观和学习，使我对美国大学图书馆文献资料的完备和浩瀚早有思想准备，但是真正进入东亚图书馆内部近距离参观，还是令我这个中国老图书馆员惊诧不已，其藏书之多、之全、之广，是绝不负“璀璨之珠”盛名的。你能想到的、想不到的，这里几乎都有，宗谱县志、统计年鉴、艺术画册、佛教经典、历史图片等都公开陈列供人借阅，还有罕见的中国地方志、清至民国早期政治、军事、经济历史记载等珍贵文献资料，应有尽有。甚至有许多的文革史的资料，包括人物传记、口述、事件研究、图片等，还有大量文革时期各派的油印小报和传单。 如今，东亚图书馆拥有北美最多的宋元古籍善本；有北美大学中最大的中文金石拓片收藏；有“清华国学院四大导师”之一的赵元任先生一生的档案收藏；有17到20世纪的中国地图2000余件。由于该馆图书资料的收藏与整理水平很高，该馆的学术地位已在美国大学同类图书馆排名中上升至第二，仅次于哈佛大学东亚图书馆。 依托于丰富的馆藏，东亚图书馆对旧金山湾区、美国乃至世界范围内的中国问题研究起到了重要支撑作用，是伯克利东亚研究的信息中心和研究基地。伯克利分校有六、七十位教授专门研究中国，是一支不可忽视的力量。现在东亚图书馆每年的藏品以大约２万件的速度增长，数字藏品和纸本藏品的总量达到了４００多万件，为伯克利的许多院系和学科提供服务。目前，东亚图书馆正在抓紧对各种珍贵文献进行数字化整理，将来会陆续对公众开放。 值得一提的是，这也是该大学历史上第一座全部依靠私人捐赠建成的大楼，代表了伯克利精神，即卓越的学术和多元的文化，同时也反映了伯克利分校作为世界级学府的地位，现在东亚图书馆已成为伯克利校园中心的一个亮丽地标。 在学术会议室坐下以后（注意看墙上的装饰画），由Stacy Reardon and Cody Hennesy两位馆员为我们作了有关“数字人文”方面的学术介绍。印象最深的是几个案例，一个是有关艺术史研究的，通过达芬奇的画，得出光线和窗户的关系；另一个是有关路易斯安娜州奴隶逃亡的故事，通过对所有文字的数位化分析，得出奴隶逃亡路线及他们的社会关系；还有一个是用机器学习的方法，分析社交媒体上的仇恨言论。国内的会议上还没有听到这样的报告，感觉他们做的非常扎实。负责接待我们的东亚图书馆典藏部负责人何剑叶与我们进行了热烈交流，非常详细地回答了大家的问题。中午何老师本来有约，但为了多一点时间和我们交流，推掉了约会，抓紧午餐的点滴时间为我们介绍东亚图书馆在数字人文、学科服务方面的做法。在谈到如何做好学科服务时，何老师说，到课堂上去，去讲课，去培训；到教学中心去，去跟教授讨论，告诉他们我们能做什么，弄清楚他们究竟需要什么服务；关于“如何保持馆员新知？”何老师说，每年暑期都会有各种类型的研讨班、进修班、培训班，是馆员充电学习的最好时机，每个馆员都有义务不断提升自己。 何剑叶老师思维敏捷，语速快，精力充沛，热情真挚，她那高于常人的自律和极度敬业的精神，给我留下了深刻的印象。 在学界享有盛誉的加州大学伯克利分校，其图书馆系统共有一个总馆和四十多个专业分馆组成，东亚图书馆只是其中之一。下篇我们继续分享伯克利分校森林般的美丽校园、主图书馆、以及本科生图书馆。我们还将听一听著名的田长霖校长的故事，现场看一看传说中的诺贝尔奖获者的车位。 "}}